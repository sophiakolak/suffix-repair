{"prefix": "import re\nimport logging\nimport six\n\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request, XmlResponse\nfrom scrapy.utils.sitemap import Sitemap, sitemap_urls_from_robots\nfrom scrapy.utils.gz import gunzip, is_gzipped\n\nlogger = logging.getLogger(__name__)\n\n\nclass SitemapSpider(Spider):\n\n    sitemap_urls = ()\n    sitemap_rules = [('', 'parse')]\n    sitemap_follow = ['']\n    sitemap_alternate_links = False\n\n    def __init__(self, *a, **kw):\n        super(SitemapSpider, self).__init__(*a, **kw)\n        self._cbs = []\n        for r, c in self.sitemap_rules:\n            if isinstance(c, six.string_types):\n                c = getattr(self, c)\n            self._cbs.append((regex(r), c))\n        self._follow = [regex(x) for x in self.sitemap_follow]\n\n    def start_requests(self):\n        for url in self.sitemap_urls:\n            yield Request(url, self._parse_sitemap)\n\n    def _parse_sitemap(self, response):\n        if response.url.endswith('/robots.txt'):\n", "suffix": "                yield Request(url, callback=self._parse_sitemap)\n        else:\n            body = self._get_sitemap_body(response)\n            if body is None:\n                logger.warning(\"Ignoring invalid sitemap: %(response)s\",\n                               {'response': response}, extra={'spider': self})\n                return\n\n            s = Sitemap(body)\n            if s.type == 'sitemapindex':\n                for loc in iterloc(s, self.sitemap_alternate_links):\n                    if any(x.search(loc) for x in self._follow):\n                        yield Request(loc, callback=self._parse_sitemap)\n            elif s.type == 'urlset':\n                for loc in iterloc(s):\n                    for r, c in self._cbs:\n                        if r.search(loc):\n                            yield Request(loc, callback=c)\n                            break\n\n    def _get_sitemap_body(self, response):\n        \"\"\"Return the sitemap body contained in the given response,\n        or None if the response is not a sitemap.\n        \"\"\"\n        if isinstance(response, XmlResponse):\n            return response.body\n        elif is_gzipped(response):\n            return gunzip(response.body)\n        elif response.url.endswith('.xml'):\n            return response.body\n        elif response.url.endswith('.xml.gz'):\n            return gunzip(response.body)\n\n\ndef regex(x):\n    if isinstance(x, six.string_types):\n        return re.compile(x)\n    return x\n\n\n", "long_prefix": ["import re\nimport logging\nimport six\n\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request, XmlResponse\nfrom scrapy.utils.sitemap import Sitemap, sitemap_urls_from_robots\nfrom scrapy.utils.gz import gunzip, is_gzipped\n\nlogger = logging.getLogger(__name__)\n\n\nclass SitemapSpider(Spider):\n\n    sitemap_urls = ()\n    sitemap_rules = [('', 'parse')]\n    sitemap_follow = ['']\n    sitemap_alternate_links = False\n\n    def __init__(self, *a, **kw):\n        super(SitemapSpider, self).__init__(*a, **kw)\n        self._cbs = []\n        for r, c in self.sitemap_rules:\n            if isinstance(c, six.string_types):\n                c = getattr(self, c)\n            self._cbs.append((regex(r), c))\n        self._follow = [regex(x) for x in self.sitemap_follow]\n\n    def start_requests(self):\n        for url in self.sitemap_urls:\n            yield Request(url, self._parse_sitemap)\n\n    def _parse_sitemap(self, response):\n        if response.url.endswith('/robots.txt'):\n", "                yield Request(url, callback=self._parse_sitemap)\n        else:\n            body = self._get_sitemap_body(response)\n            if body is None:\n                logger.warning(\"Ignoring invalid sitemap: %(response)s\",\n                               {'response': response}, extra={'spider': self})\n                return\n\n            s = Sitemap(body)\n            if s.type == 'sitemapindex':\n                for loc in iterloc(s, self.sitemap_alternate_links):\n                    if any(x.search(loc) for x in self._follow):\n                        yield Request(loc, callback=self._parse_sitemap)\n            elif s.type == 'urlset':\n                for loc in iterloc(s):\n                    for r, c in self._cbs:\n                        if r.search(loc):\n                            yield Request(loc, callback=c)\n                            break\n\n    def _get_sitemap_body(self, response):\n        \"\"\"Return the sitemap body contained in the given response,\n        or None if the response is not a sitemap.\n        \"\"\"\n        if isinstance(response, XmlResponse):\n            return response.body\n        elif is_gzipped(response):\n            return gunzip(response.body)\n        elif response.url.endswith('.xml'):\n            return response.body\n        elif response.url.endswith('.xml.gz'):\n            return gunzip(response.body)\n\n\ndef regex(x):\n    if isinstance(x, six.string_types):\n        return re.compile(x)\n    return x\n\n\n"]}