{"prefix": "    def get_pending_tasks(self):\n        return itertools.chain.from_iterable(six.itervalues(self._status_tasks[status])\n                                             for status in [PENDING, RUNNING])\n\n    def num_pending_tasks(self):\n        \"\"\"\n        Return how many tasks are PENDING + RUNNING. O(1).\n        \"\"\"\n        return len(self._status_tasks[PENDING]) + len(self._status_tasks[RUNNING])\n\n    def get_task(self, task_id, default=None, setdefault=None):\n        if setdefault:\n            task = self._tasks.setdefault(task_id, setdefault)\n            self._status_tasks[task.status][task.id] = task\n            return task\n        else:\n            return self._tasks.get(task_id, default)\n\n    def has_task(self, task_id):\n        return task_id in self._tasks\n\n    def re_enable(self, task, config=None):\n        task.scheduler_disable_time = None\n        task.failures.clear()\n        if config:\n            self.set_status(task, FAILED, config)\n            task.failures.clear()\n\n    def set_status(self, task, new_status, config=None):\n        if new_status == FAILED:\n            assert config is not None\n\n        if new_status == DISABLED and task.status == RUNNING:\n            return\n\n        if task.status == DISABLED:\n            if new_status == DONE:\n                self.re_enable(task)\n\n            # don't allow workers to override a scheduler disable\n", "suffix": "                return\n\n        if new_status == FAILED and task.can_disable() and task.status != DISABLED:\n            task.add_failure()\n            if task.has_excessive_failures():\n                task.scheduler_disable_time = time.time()\n                new_status = DISABLED\n                notifications.send_error_email(\n                    'Luigi Scheduler: DISABLED {task} due to excessive failures'.format(task=task.id),\n                    '{task} failed {failures} times in the last {window} seconds, so it is being '\n                    'disabled for {persist} seconds'.format(\n                        failures=config.disable_failures,\n                        task=task.id,\n                        window=config.disable_window,\n                        persist=config.disable_persist,\n                    ))\n        elif new_status == DISABLED:\n            task.scheduler_disable_time = None\n\n        self._status_tasks[task.status].pop(task.id)\n        self._status_tasks[new_status][task.id] = task\n        task.status = new_status\n\n    def fail_dead_worker_task(self, task, config, assistants):\n        # If a running worker disconnects, tag all its jobs as FAILED and subject it to the same retry logic\n        if task.status == RUNNING and task.worker_running and task.worker_running not in task.stakeholders | assistants:\n            logger.info(\"Task %r is marked as running by disconnected worker %r -> marking as \"\n                        \"FAILED with retry delay of %rs\", task.id, task.worker_running,\n                        config.retry_delay)\n            task.worker_running = None\n            self.set_status(task, FAILED, config)\n            task.retry = time.time() + config.retry_delay\n\n    def prune(self, task, config):\n        remove = False\n\n        # Mark tasks with no remaining active stakeholders for deletion\n        if not task.stakeholders:\n            if task.remove is None:\n                logger.info(\"Task %r has stakeholders %r but none remain connected -> will remove \"\n", "long_prefix": ["            for task in six.itervalues(self._tasks):\n                self._status_tasks[task.status][task.id] = task\n\n            # Convert from old format\n            # TODO: this is really ugly, we need something more future-proof\n            # Every time we add an attribute to the Worker or Task class, this\n            # code needs to be updated\n\n            # Compatibility since 2014-06-02\n            for k, v in six.iteritems(self._active_workers):\n                if isinstance(v, float):\n                    self._active_workers[k] = Worker(worker_id=k, last_active=v)\n\n            # Compatibility since 2015-05-28\n            if any(not hasattr(w, 'tasks') for k, w in six.iteritems(self._active_workers)):\n                # If you load from an old format where Workers don't contain tasks.\n                for k, worker in six.iteritems(self._active_workers):\n                    worker.tasks = set()\n                for task in six.itervalues(self._tasks):\n                    for worker_id in task.workers:\n                        self._active_workers[worker_id].tasks.add(task)\n\n            # Compatibility since 2015-04-28\n            if any(not hasattr(t, 'disable_hard_timeout') for t in six.itervalues(self._tasks)):\n                for t in six.itervalues(self._tasks):\n                    t.disable_hard_timeout = None\n        else:\n            logger.info(\"No prior state file exists at %s. Starting with clean slate\", self._state_path)\n\n    def get_active_tasks(self, status=None):\n        if status:\n            for task in six.itervalues(self._status_tasks[status]):\n                yield task\n        else:\n            for task in six.itervalues(self._tasks):\n                yield task\n\n    def get_running_tasks(self):\n        return six.itervalues(self._status_tasks[RUNNING])\n\n    def get_pending_tasks(self):\n        return itertools.chain.from_iterable(six.itervalues(self._status_tasks[status])\n                                             for status in [PENDING, RUNNING])\n\n    def num_pending_tasks(self):\n        \"\"\"\n        Return how many tasks are PENDING + RUNNING. O(1).\n        \"\"\"\n        return len(self._status_tasks[PENDING]) + len(self._status_tasks[RUNNING])\n\n    def get_task(self, task_id, default=None, setdefault=None):\n        if setdefault:\n            task = self._tasks.setdefault(task_id, setdefault)\n            self._status_tasks[task.status][task.id] = task\n            return task\n        else:\n            return self._tasks.get(task_id, default)\n\n    def has_task(self, task_id):\n        return task_id in self._tasks\n\n    def re_enable(self, task, config=None):\n        task.scheduler_disable_time = None\n        task.failures.clear()\n        if config:\n            self.set_status(task, FAILED, config)\n            task.failures.clear()\n\n    def set_status(self, task, new_status, config=None):\n        if new_status == FAILED:\n            assert config is not None\n\n        if new_status == DISABLED and task.status == RUNNING:\n            return\n\n        if task.status == DISABLED:\n            if new_status == DONE:\n                self.re_enable(task)\n\n            # don't allow workers to override a scheduler disable\n", "                return\n\n        if new_status == FAILED and task.can_disable() and task.status != DISABLED:\n            task.add_failure()\n            if task.has_excessive_failures():\n                task.scheduler_disable_time = time.time()\n                new_status = DISABLED\n                notifications.send_error_email(\n                    'Luigi Scheduler: DISABLED {task} due to excessive failures'.format(task=task.id),\n                    '{task} failed {failures} times in the last {window} seconds, so it is being '\n                    'disabled for {persist} seconds'.format(\n                        failures=config.disable_failures,\n                        task=task.id,\n                        window=config.disable_window,\n                        persist=config.disable_persist,\n                    ))\n        elif new_status == DISABLED:\n            task.scheduler_disable_time = None\n\n        self._status_tasks[task.status].pop(task.id)\n        self._status_tasks[new_status][task.id] = task\n        task.status = new_status\n\n    def fail_dead_worker_task(self, task, config, assistants):\n        # If a running worker disconnects, tag all its jobs as FAILED and subject it to the same retry logic\n        if task.status == RUNNING and task.worker_running and task.worker_running not in task.stakeholders | assistants:\n            logger.info(\"Task %r is marked as running by disconnected worker %r -> marking as \"\n                        \"FAILED with retry delay of %rs\", task.id, task.worker_running,\n                        config.retry_delay)\n            task.worker_running = None\n            self.set_status(task, FAILED, config)\n            task.retry = time.time() + config.retry_delay\n\n    def prune(self, task, config):\n        remove = False\n\n        # Mark tasks with no remaining active stakeholders for deletion\n        if not task.stakeholders:\n            if task.remove is None:\n                logger.info(\"Task %r has stakeholders %r but none remain connected -> will remove \"\n"]}