{"prefix": "        default=1,\n        description=\"Maximum number of workers running the same command\")\n    no_lock = parameter.BoolParameter(\n        default=False,\n        description='Ignore if similar process is already running')\n    lock_pid_dir = parameter.Parameter(\n        default=os.path.join(tempfile.gettempdir(), 'luigi'),\n        description='Directory to store the pid file')\n    take_lock = parameter.BoolParameter(\n        default=False,\n        description='Signal other processes to stop getting work if already running')\n    workers = parameter.IntParameter(\n        default=1,\n        description='Maximum number of parallel tasks to run')\n    logging_conf_file = parameter.Parameter(\n        default=None,\n        description='Configuration file for logging')\n    module = parameter.Parameter(\n        default=None,\n        description='Used for dynamic loading of modules',\n        always_in_help=True)\n    parallel_scheduling = parameter.BoolParameter(\n        default=False,\n        description='Use multiprocessing to do scheduling in parallel.')\n    assistant = parameter.BoolParameter(\n        default=False,\n        description='Run any task from the scheduler.')\n    help = parameter.BoolParameter(\n        default=False,\n        description='Show most common flags and all task-specific flags',\n        always_in_help=True)\n    help_all = parameter.BoolParameter(\n        default=False,\n        description='Show all command line flags',\n        always_in_help=True)\n\n\nclass _WorkerSchedulerFactory(object):\n\n    def create_local_scheduler(self):\n", "suffix": "\n    def create_remote_scheduler(self, url):\n        return rpc.RemoteScheduler(url)\n\n    def create_worker(self, scheduler, worker_processes, assistant=False):\n        return worker.Worker(\n            scheduler=scheduler, worker_processes=worker_processes, assistant=assistant)\n\n\ndef _schedule_and_run(tasks, worker_scheduler_factory=None, override_defaults=None):\n    \"\"\"\n    :param tasks:\n    :param worker_scheduler_factory:\n    :param override_defaults:\n    :return: True if all tasks and their dependencies were successfully run (or already completed);\n             False if any error occurred.\n    \"\"\"\n\n    if worker_scheduler_factory is None:\n        worker_scheduler_factory = _WorkerSchedulerFactory()\n    if override_defaults is None:\n        override_defaults = {}\n    env_params = core(**override_defaults)\n    # search for logging configuration path first on the command line, then\n    # in the application config file\n    logging_conf = env_params.logging_conf_file\n    if logging_conf is not None and not os.path.exists(logging_conf):\n        raise Exception(\n            \"Error: Unable to locate specified logging configuration file!\"\n        )\n\n    if not configuration.get_config().getboolean(\n            'core', 'no_configure_logging', False):\n        setup_interface_logging(logging_conf)\n\n    kill_signal = signal.SIGUSR1 if env_params.take_lock else None\n    if (not env_params.no_lock and\n            not(lock.acquire_for(env_params.lock_pid_dir, env_params.lock_size, kill_signal))):\n        raise PidLockAlreadyTakenExit()\n\n", "long_prefix": ["\n        formatter = logging.Formatter('%(levelname)s: %(message)s')\n        stream_handler.setFormatter(formatter)\n\n        logger.addHandler(stream_handler)\n    else:\n        logging.config.fileConfig(conf_file, disable_existing_loggers=False)\n\n    setup_interface_logging.has_run = True\n\n\nclass core(task.Config):\n\n    ''' Keeps track of a bunch of environment params.\n\n    Uses the internal luigi parameter mechanism.\n    The nice thing is that we can instantiate this class\n    and get an object with all the environment variables set.\n    This is arguably a bit of a hack.\n    '''\n    use_cmdline_section = False\n\n    local_scheduler = parameter.BoolParameter(\n        default=False,\n        description='Use an in-memory central scheduler. Useful for testing.',\n        always_in_help=True)\n    scheduler_host = parameter.Parameter(\n        default='localhost',\n        description='Hostname of machine running remote scheduler',\n        config_path=dict(section='core', name='default-scheduler-host'))\n    scheduler_port = parameter.IntParameter(\n        default=8082,\n        description='Port of remote scheduler api process',\n        config_path=dict(section='core', name='default-scheduler-port'))\n    scheduler_url = parameter.Parameter(\n        default=None,\n        description='Full path to remote scheduler',\n        config_path=dict(section='core', name='default-scheduler-url'),\n    )\n    lock_size = parameter.IntParameter(\n        default=1,\n        description=\"Maximum number of workers running the same command\")\n    no_lock = parameter.BoolParameter(\n        default=False,\n        description='Ignore if similar process is already running')\n    lock_pid_dir = parameter.Parameter(\n        default=os.path.join(tempfile.gettempdir(), 'luigi'),\n        description='Directory to store the pid file')\n    take_lock = parameter.BoolParameter(\n        default=False,\n        description='Signal other processes to stop getting work if already running')\n    workers = parameter.IntParameter(\n        default=1,\n        description='Maximum number of parallel tasks to run')\n    logging_conf_file = parameter.Parameter(\n        default=None,\n        description='Configuration file for logging')\n    module = parameter.Parameter(\n        default=None,\n        description='Used for dynamic loading of modules',\n        always_in_help=True)\n    parallel_scheduling = parameter.BoolParameter(\n        default=False,\n        description='Use multiprocessing to do scheduling in parallel.')\n    assistant = parameter.BoolParameter(\n        default=False,\n        description='Run any task from the scheduler.')\n    help = parameter.BoolParameter(\n        default=False,\n        description='Show most common flags and all task-specific flags',\n        always_in_help=True)\n    help_all = parameter.BoolParameter(\n        default=False,\n        description='Show all command line flags',\n        always_in_help=True)\n\n\nclass _WorkerSchedulerFactory(object):\n\n    def create_local_scheduler(self):\n", "\n    def create_remote_scheduler(self, url):\n        return rpc.RemoteScheduler(url)\n\n    def create_worker(self, scheduler, worker_processes, assistant=False):\n        return worker.Worker(\n            scheduler=scheduler, worker_processes=worker_processes, assistant=assistant)\n\n\ndef _schedule_and_run(tasks, worker_scheduler_factory=None, override_defaults=None):\n    \"\"\"\n    :param tasks:\n    :param worker_scheduler_factory:\n    :param override_defaults:\n    :return: True if all tasks and their dependencies were successfully run (or already completed);\n             False if any error occurred.\n    \"\"\"\n\n    if worker_scheduler_factory is None:\n        worker_scheduler_factory = _WorkerSchedulerFactory()\n    if override_defaults is None:\n        override_defaults = {}\n    env_params = core(**override_defaults)\n    # search for logging configuration path first on the command line, then\n    # in the application config file\n    logging_conf = env_params.logging_conf_file\n    if logging_conf is not None and not os.path.exists(logging_conf):\n        raise Exception(\n            \"Error: Unable to locate specified logging configuration file!\"\n        )\n\n    if not configuration.get_config().getboolean(\n            'core', 'no_configure_logging', False):\n        setup_interface_logging(logging_conf)\n\n    kill_signal = signal.SIGUSR1 if env_params.take_lock else None\n    if (not env_params.no_lock and\n            not(lock.acquire_for(env_params.lock_pid_dir, env_params.lock_size, kill_signal))):\n        raise PidLockAlreadyTakenExit()\n\n"]}