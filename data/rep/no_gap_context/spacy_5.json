{"prefix": "        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"_rehearsal_model\"):\n                proc._rehearsal_model = deepcopy(proc.model)\n        return self._optimizer\n\n    def evaluate(\n        self, docs_golds, verbose=False, batch_size=256, scorer=None, component_cfg=None\n    ):\n        \"\"\"Evaluate a model's pipeline components.\n\n        docs_golds (iterable): Tuples of `Doc` and `GoldParse` objects.\n        verbose (bool): Print debugging information.\n        batch_size (int): Batch size to use.\n        scorer (Scorer): Optional `Scorer` to use. If not passed in, a new one\n            will be created.\n        component_cfg (dict): An optional dictionary with extra keyword\n            arguments for specific components.\n        RETURNS (Scorer): The scorer containing the evaluation results.\n\n        DOCS: https://spacy.io/api/language#evaluate\n        \"\"\"\n        if scorer is None:\n            scorer = Scorer(pipeline=self.pipeline)\n        if component_cfg is None:\n            component_cfg = {}\n        docs, golds = zip(*docs_golds)\n        docs = [\n            self.make_doc(doc) if isinstance(doc, basestring_) else doc for doc in docs\n        ]\n        golds = list(golds)\n        for name, pipe in self.pipeline:\n            kwargs = component_cfg.get(name, {})\n            kwargs.setdefault(\"batch_size\", batch_size)\n            if not hasattr(pipe, \"pipe\"):\n", "suffix": "            else:\n                docs = pipe.pipe(docs, **kwargs)\n        for doc, gold in zip(docs, golds):\n            if not isinstance(gold, GoldParse):\n                gold = GoldParse(doc, **gold)\n            if verbose:\n                print(doc)\n            kwargs = component_cfg.get(\"scorer\", {})\n            kwargs.setdefault(\"verbose\", verbose)\n            scorer.score(doc, gold, **kwargs)\n        return scorer\n\n    @contextmanager\n    def use_params(self, params, **cfg):\n        \"\"\"Replace weights of models in the pipeline with those provided in the\n        params dictionary. Can be used as a contextmanager, in which case,\n        models go back to their original weights after the block.\n\n        params (dict): A dictionary of parameters keyed by model ID.\n        **cfg: Config parameters.\n\n        EXAMPLE:\n            >>> with nlp.use_params(optimizer.averages):\n            >>>     nlp.to_disk('/tmp/checkpoint')\n        \"\"\"\n        contexts = [\n            pipe.use_params(params)\n            for name, pipe in self.pipeline\n            if hasattr(pipe, \"use_params\")\n        ]\n        # TODO: Having trouble with contextlib\n        # Workaround: these aren't actually context managers atm.\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass\n        yield\n        for context in contexts:\n            try:\n", "long_prefix": ["                for annots, _ in annots_brackets:\n                    for word in annots[1]:\n                        _ = self.vocab[word]  # noqa: F841\n        if cfg.get(\"device\", -1) >= 0:\n            util.use_gpu(cfg[\"device\"])\n            if self.vocab.vectors.data.shape[1] >= 1:\n                self.vocab.vectors.data = Model.ops.asarray(self.vocab.vectors.data)\n        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        if component_cfg is None:\n            component_cfg = {}\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"begin_training\"):\n                kwargs = component_cfg.get(name, {})\n                kwargs.update(cfg)\n                proc.begin_training(\n                    get_gold_tuples,\n                    pipeline=self.pipeline,\n                    sgd=self._optimizer,\n                    **kwargs\n                )\n        return self._optimizer\n\n    def resume_training(self, sgd=None, **cfg):\n        \"\"\"Continue training a pretrained model.\n\n        Create and return an optimizer, and initialize \"rehearsal\" for any pipeline\n        component that has a .rehearse() method. Rehearsal is used to prevent\n        models from \"forgetting\" their initialised \"knowledge\". To perform\n        rehearsal, collect samples of text you want the models to retain performance\n        on, and call nlp.rehearse() with a batch of Doc objects.\n        \"\"\"\n        if cfg.get(\"device\", -1) >= 0:\n            util.use_gpu(cfg[\"device\"])\n            if self.vocab.vectors.data.shape[1] >= 1:\n                self.vocab.vectors.data = Model.ops.asarray(self.vocab.vectors.data)\n        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"_rehearsal_model\"):\n                proc._rehearsal_model = deepcopy(proc.model)\n        return self._optimizer\n\n    def evaluate(\n        self, docs_golds, verbose=False, batch_size=256, scorer=None, component_cfg=None\n    ):\n        \"\"\"Evaluate a model's pipeline components.\n\n        docs_golds (iterable): Tuples of `Doc` and `GoldParse` objects.\n        verbose (bool): Print debugging information.\n        batch_size (int): Batch size to use.\n        scorer (Scorer): Optional `Scorer` to use. If not passed in, a new one\n            will be created.\n        component_cfg (dict): An optional dictionary with extra keyword\n            arguments for specific components.\n        RETURNS (Scorer): The scorer containing the evaluation results.\n\n        DOCS: https://spacy.io/api/language#evaluate\n        \"\"\"\n        if scorer is None:\n            scorer = Scorer(pipeline=self.pipeline)\n        if component_cfg is None:\n            component_cfg = {}\n        docs, golds = zip(*docs_golds)\n        docs = [\n            self.make_doc(doc) if isinstance(doc, basestring_) else doc for doc in docs\n        ]\n        golds = list(golds)\n        for name, pipe in self.pipeline:\n            kwargs = component_cfg.get(name, {})\n            kwargs.setdefault(\"batch_size\", batch_size)\n            if not hasattr(pipe, \"pipe\"):\n", "            else:\n                docs = pipe.pipe(docs, **kwargs)\n        for doc, gold in zip(docs, golds):\n            if not isinstance(gold, GoldParse):\n                gold = GoldParse(doc, **gold)\n            if verbose:\n                print(doc)\n            kwargs = component_cfg.get(\"scorer\", {})\n            kwargs.setdefault(\"verbose\", verbose)\n            scorer.score(doc, gold, **kwargs)\n        return scorer\n\n    @contextmanager\n    def use_params(self, params, **cfg):\n        \"\"\"Replace weights of models in the pipeline with those provided in the\n        params dictionary. Can be used as a contextmanager, in which case,\n        models go back to their original weights after the block.\n\n        params (dict): A dictionary of parameters keyed by model ID.\n        **cfg: Config parameters.\n\n        EXAMPLE:\n            >>> with nlp.use_params(optimizer.averages):\n            >>>     nlp.to_disk('/tmp/checkpoint')\n        \"\"\"\n        contexts = [\n            pipe.use_params(params)\n            for name, pipe in self.pipeline\n            if hasattr(pipe, \"use_params\")\n        ]\n        # TODO: Having trouble with contextlib\n        # Workaround: these aren't actually context managers atm.\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass\n        yield\n        for context in contexts:\n            try:\n"]}