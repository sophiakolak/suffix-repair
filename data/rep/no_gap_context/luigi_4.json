{"prefix": "                coldefs=coldefs,\n                table_attributes=self.table_attributes)\n\n            connection.cursor().execute(query)\n        else:\n            raise ValueError(\"create_table() found no columns for %r\"\n                             % self.table)\n\n    def run(self):\n        \"\"\"\n        If the target table doesn't exist, self.create_table\n        will be called to attempt to create the table.\n        \"\"\"\n        if not (self.table):\n            raise Exception(\"table need to be specified\")\n\n        path = self.s3_load_path()\n        output = self.output()\n        connection = output.connect()\n        cursor = connection.cursor()\n\n        self.init_copy(connection)\n        self.copy(cursor, path)\n        self.post_copy(cursor)\n\n        # update marker table\n        output.touch(connection)\n        connection.commit()\n\n        # commit and clean up\n        connection.close()\n\n    def copy(self, cursor, f):\n        \"\"\"\n        Defines copying from s3 into redshift.\n\n        If both key-based and role-based credentials are provided, role-based will be used.\n        \"\"\"\n        logger.info(\"Inserting file: %s\", f)\n        colnames = ''\n", "suffix": "            colnames = \",\".join([x[0] for x in self.columns])\n            colnames = '({})'.format(colnames)\n\n        cursor.execute(\"\"\"\n         COPY {table} {colnames} from '{source}'\n         CREDENTIALS '{creds}'\n         {options}\n         ;\"\"\".format(\n            table=self.table,\n            colnames=colnames,\n            source=f,\n            creds=self._credentials(),\n            options=self.copy_options)\n        )\n\n    def output(self):\n        \"\"\"\n        Returns a RedshiftTarget representing the inserted dataset.\n\n        Normally you don't override this.\n        \"\"\"\n        return RedshiftTarget(\n            host=self.host,\n            database=self.database,\n            user=self.user,\n            password=self.password,\n            table=self.table,\n            update_id=self.update_id)\n\n    def does_table_exist(self, connection):\n        \"\"\"\n        Determine whether the table already exists.\n        \"\"\"\n\n        if '.' in self.table:\n            query = (\"select 1 as table_exists \"\n                     \"from information_schema.tables \"\n                     \"where table_schema = lower(%s) and table_name = lower(%s) limit 1\")\n        else:\n            query = (\"select 1 as table_exists \"\n", "long_prefix": ["\n        If overridden, use the provided connection object for\n        setting up the table in order to create the table and\n        insert data using the same transaction.\n        \"\"\"\n        if len(self.columns[0]) == 1:\n            # only names of columns specified, no types\n            raise NotImplementedError(\"create_table() not implemented \"\n                                      \"for %r and columns types not \"\n                                      \"specified\" % self.table)\n        elif len(self.columns[0]) == 2:\n            # if columns is specified as (name, type) tuples\n            coldefs = ','.join(\n                '{name} {type}'.format(\n                    name=name,\n                    type=type) for name, type in self.columns\n            )\n            query = (\"CREATE {type} TABLE \"\n                     \"{table} ({coldefs}) \"\n                     \"{table_attributes}\").format(\n                type=self.table_type,\n                table=self.table,\n                coldefs=coldefs,\n                table_attributes=self.table_attributes)\n\n            connection.cursor().execute(query)\n        elif len(self.columns[0]) == 3:\n            # if columns is specified as (name, type, encoding) tuples\n            # possible column encodings: https://docs.aws.amazon.com/redshift/latest/dg/c_Compression_encodings.html\n            coldefs = ','.join(\n                '{name} {type} ENCODE {encoding}'.format(\n                    name=name,\n                    type=type,\n                    encoding=encoding) for name, type, encoding in self.columns\n            )\n            query = (\"CREATE {type} TABLE \"\n                     \"{table} ({coldefs}) \"\n                     \"{table_attributes}\").format(\n                type=self.table_type,\n                table=self.table,\n                coldefs=coldefs,\n                table_attributes=self.table_attributes)\n\n            connection.cursor().execute(query)\n        else:\n            raise ValueError(\"create_table() found no columns for %r\"\n                             % self.table)\n\n    def run(self):\n        \"\"\"\n        If the target table doesn't exist, self.create_table\n        will be called to attempt to create the table.\n        \"\"\"\n        if not (self.table):\n            raise Exception(\"table need to be specified\")\n\n        path = self.s3_load_path()\n        output = self.output()\n        connection = output.connect()\n        cursor = connection.cursor()\n\n        self.init_copy(connection)\n        self.copy(cursor, path)\n        self.post_copy(cursor)\n\n        # update marker table\n        output.touch(connection)\n        connection.commit()\n\n        # commit and clean up\n        connection.close()\n\n    def copy(self, cursor, f):\n        \"\"\"\n        Defines copying from s3 into redshift.\n\n        If both key-based and role-based credentials are provided, role-based will be used.\n        \"\"\"\n        logger.info(\"Inserting file: %s\", f)\n        colnames = ''\n", "            colnames = \",\".join([x[0] for x in self.columns])\n            colnames = '({})'.format(colnames)\n\n        cursor.execute(\"\"\"\n         COPY {table} {colnames} from '{source}'\n         CREDENTIALS '{creds}'\n         {options}\n         ;\"\"\".format(\n            table=self.table,\n            colnames=colnames,\n            source=f,\n            creds=self._credentials(),\n            options=self.copy_options)\n        )\n\n    def output(self):\n        \"\"\"\n        Returns a RedshiftTarget representing the inserted dataset.\n\n        Normally you don't override this.\n        \"\"\"\n        return RedshiftTarget(\n            host=self.host,\n            database=self.database,\n            user=self.user,\n            password=self.password,\n            table=self.table,\n            update_id=self.update_id)\n\n    def does_table_exist(self, connection):\n        \"\"\"\n        Determine whether the table already exists.\n        \"\"\"\n\n        if '.' in self.table:\n            query = (\"select 1 as table_exists \"\n                     \"from information_schema.tables \"\n                     \"where table_schema = lower(%s) and table_name = lower(%s) limit 1\")\n        else:\n            query = (\"select 1 as table_exists \"\n"]}