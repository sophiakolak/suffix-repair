{"candidate": "", "entropy": 13.731087108759}
{"candidate": "        # property, for now, slow to look up\n", "entropy": 6.505518219354}
{"candidate": "        \"\"\" property cache for the indexer engine \"\"\"\n\n        from pandas.core.indexes.period import Engine\n\n        return Engine(lambda: self.asi8, len(self))\n\n    def _maybe_cast_slice_bound(self, label, side, kind):\n        \"\"\"\n        If label is a string, cast it to datetime according to resolution.\n        \"\"\"\n        assert kind in [\"loc\", \"getitem\", None]\n\n       ", "entropy": 28.309956821346596}
{"candidate": "        from pandas.core.indexes.period import PeriodEngine\n\n        return PeriodEngine(lambda: self, len(self))\n\n    @cache_readonly\n    def _resolution_obj(self):\n        return Resolution(self.freq)\n\n    def _maybe_cast_slice_bound(self, label, side, kind):\n        \"\"\"\n        If label is a string representing a freq, cast it to Period.ordinal\n       ", "entropy": 28.8093613467722}
{"candidate": "        \"\"\"\n        We use a blocking lock instead of a non-blocking lock\n        to avoid a deadlock when using PeriodIndex._engine in a\n        worker thread, GH#32718\n        \"\"\"\n        with self._engine_lock:\n            if self._engine_type is None:\n                self._set_engine(self._engine_type)\n        return self._engine\n\n    def _engine_type_doc(self) -> str:\n", "entropy": 50.6950827427218}
{"candidate": "        # property, for consistency with DatetimeIndex\n        return libperiod.PeriodEngine(self.asi8, freq=self.freq, start=self.start)\n\n    @Appender(Index.get_loc.__doc__)\n    def get_loc(self, key, method=None, tolerance=None):\n        \"\"\"\n        Get integer location for requested label\n\n        Returns\n        -------\n        loc : int\n        \"\"\"", "entropy": 29.672598321922504}
{"candidate": "        # property, for compatibility\n        return self._engine_type(self.freq, len(self))\n\n    @doc(Index._shallow_copy)\n    def _shallow_copy(self, values=None, freq=None, name=lib.no_default):\n        if freq is None:\n            freq = self.freq\n            if freq is None:\n                freq = liboffsets.d", "entropy": 31.735061960491176}
{"candidate": "        return self._engine_type(self._data, len(self))\n\n    @doc(Index.get_loc)\n    def get_loc(self, key: Any) -> HashTableType:\n        if self.is_monotonic and is_scalar(key):\n            ordinal = self._ordinal_for_value(key)\n            if ordinal in self._engine:\n                return self._engine.get_", "entropy": 44.700710394913514}
{"candidate": "        return self._engine_type(self.freq, len(self))\n\n    def __getitem__(self, key):\n        \"\"\"\n        This getitem defers to the underlying array, which by-definition can\n        only handle list-likes, slices, and integer scalars\n        \"\"\"\n        if is_integer(key):\n            return self._maybe_mask_results(self._int64index[key], indexer=[key", "entropy": 21.8189521671122}
{"candidate": "        \"\"\" property for the lookup engine \"\"\"\n        return PeriodEngine(lambda s: s, len(self))\n\n    def _maybe_cache_insert(self, key, value):\n        pass\n\n    def _maybe_cache(self, value):\n        \"\"\"\n        If we have a cache, insert value into the cache.\n        Otherwise return the value\n        \"\"\"\n        return value\n\n    def get_value(self, series, key):\n       ", "entropy": 46.33657598127042}
{"candidate": "        if is_period_dtype(self):\n            return self.asi8\n        return self.astype(object).values\n\n    @cache_readonly\n    def _engine_type(self):\n        return self._engine.dtype\n\n    def get_value(self, series, key):\n        \"\"\"\n        Fast lookup of value from 1-dimensional ndarray. Only use this if you\n        know what you're doing\n       ", "entropy": 20.42813593499241}
{"candidate": "        return PeriodIndexEngine(self)\n\n    def _get_engine(self, kind):\n        if not self.is_monotonic:\n            raise ValueError(\n                \"loss of monotonicity-\"\n                \"cannot safely perform \" + kind + \" with non-unique index\"\n            )\n        return self._engine\n\n    def _wrap_joined_index(self, joined: np.ndarray, other: np.ndarray", "entropy": 68.39088965533648}
{"candidate": "        return IndexEngine(lambda: self._values, len(self), self.freq)\n\n    @cache_readonly\n    def _engine_type(self):\n        return self._engine.get_value_engine(self.dtype)\n\n    def get_value(self, series, key):\n        k = _values_from_object(key)\n        if is_integer(k):\n            return self._engine.get_", "entropy": 31.1531962205996}
{"candidate": "        return PeriodEngine(\n            lambda period: period.ordinal,\n            len(self),\n            offset=self.freq.ordinal,\n            dtype=self.dtype,\n            fastpath=True,\n        )\n\n    @Appender(Index.__contains__.__doc__)\n    def contains(self, key: Any) -> bool:\n        hash(key)\n        try:\n            self.get", "entropy": 35.035908345880515}
{"candidate": "        \"\"\"\n        We use a blocking dictionary here to prevent recursion issues when\n        pickling.\n        \"\"\"\n        # this is basically lazy evaluation of\n        # self._int64index.indexer_at_time(self._data, self._tz)\n        return BlockPlacement(self.asi8)\n\n    def _engine_loc(self, key):\n        return self._engine[key]\n\n    @staticmethod\n    def _", "entropy": 74.32358743647396}
{"candidate": "        return PeriodEngine(self, len(self), self.dtype)\n\n    def astype(self, dtype, copy: bool = True):\n        dtype = pandas_dtype(dtype)\n        if isinstance(dtype, PeriodDtype):\n            if dtype.freq == self.freq:\n                # Same freq, ok to copy=False\n                return self._shallow_copy()\n\n            #", "entropy": 47.50197827668641}
{"candidate": "        # property, for compatibility with DatetimeIndex\n        return self._get_engine()\n\n    def _get_engine(self) -> PeriodArrayEngine:\n        return PeriodArrayEngine(self)\n\n    def _maybe_mask_results(self, result, fill_value, convert):\n        \"\"\"\n        Parameters\n        ----------\n        result : a ndarray\n        fill_value : the value to use for NA/NaT\n        convert", "entropy": 30.99246419535719}
{"candidate": "        # property, for now, slow to look up\n        return PeriodEngine(lambda s: s, len(self), self.freq)\n\n    @doc(Index.__getitem__)\n    def __getitem__(self, key):\n        if is_integer(key):\n            if is_scalar(key):\n                val = self._engine.get_value(key)\n                if val is None or isna(", "entropy": 28.207895453972892}
{"candidate": "        from pandas.core.indexes.period import _PeriodIndexEngine\n\n        return _PeriodIndexEngine(lambda: self, len(self), self.freq)\n\n    def _maybe_update_attributes(self, attrs: Dict[str, Any]) -> None:\n        \"\"\" Update Index attributes (e.g. freq) depending on op \"\"\"\n        freq = attrs[\"freq\"]\n        if freq", "entropy": 22.587641393198894}
{"candidate": "        return self._engine_type(self.freq, len(self))\n\n    @property\n    def _engine_type(self):\n        if self.freq.n > 0 or self._has_same_name(self.freq):\n            return self._engine_class(len(self), dtype=self.dtype)\n        else:\n            # Must convert negative periods to positive\n            # Don't cache these\n           ", "entropy": 67.12526494508069}
