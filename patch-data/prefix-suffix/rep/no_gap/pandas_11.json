{"candidate": "                i = level.get_indexer(key)\n                if (i == -1).any():\n                    # This key was missing, so just extend by all level values\n                    # (this will be the nan code)\n                    i = np.arange(len(level))", "entropy": 53.327771204211}
{"candidate": "                i = level.get_loc(key)\n                if is_integer(i):\n                    i = [i]", "entropy": 12.588136621357998}
{"candidate": "                i = level.get_indexer(key)\n                if (i == -1).any():\n                    raise KeyError(\n                        f\"Key length ({len(level)}) differs from index depth ({len(key)})\"\n                    )\n", "entropy": 29.227234997363}
{"candidate": "                try:\n                    codes = level.get_indexer(key)\n                except Exception:\n                    raise ValueError(\n                        \"Key length ({0}) was greater than \"\n                        \"MultiIndex lexsort depth ({1}).\".format(\n                            len(key), level.lexsort_depth\n                        )\n                    )\n", "entropy": 30.821741999572904}
{"candidate": "                i = level.get_indexer(key)", "entropy": 4.709237877725999}
{"candidate": "                # we must be an index here\n                i = level.get_indexer([key])\n                if (i == -1).any():\n                    raise ValueError(\n                        \"Key length (%d) was greater than MultiIndex \"\n                        \"lexsort depth (%d)\" % (len(hlevel), len(indexes))\n                    )", "entropy": 30.0822380107363}
{"candidate": "                i = level.get_indexer(key)", "entropy": 6.638433588332999}
{"candidate": "                i = level.get_indexer(key)", "entropy": 5.624545855726}
{"candidate": "                if key not in level:\n                    # have a new category\n                    level = level.insert(len(level), key)\n                i = level.get_loc(key)", "entropy": 27.3104722700123}
{"candidate": "                i = level.get_indexer(key)", "entropy": 5.597018732725999}
{"candidate": "                i = level.get_indexer(key)", "entropy": 4.712100263333}
{"candidate": "                i = np.searchsorted(level, key)", "entropy": 7.3587306994798}
{"candidate": "                if key not in level:\n                    # TODO: better error message\n                    raise AssertionError(\"Key length mismatch\")\n                i = level.get_loc(key)", "entropy": 23.524558804607597}
{"candidate": "                codes, categories = factorize_from_iterable(key)\n                to_concat.append(codes)\n            codes_list.append(np.concatenate(to_concat))\n\n        # these go at the end\n        if isinstance(indexes[0], MultiIndex):\n            for i, index in enumerate(indexes):\n                codes_list.append(index.codes[i])\n                levels.", "entropy": 14.558203667464003}
{"candidate": "                # if we have a nan key and non-unique index, then we have a\n                # problem\n                if isna(key) and not index.is_unique:\n                    raise ValueError(\"Key/index pairs must be unique.\")\n\n                try:\n                    i = level.get_loc(key)\n                except KeyError:\n                    # na handling\n                    if notna(key):\n                        raise\n                    if not level.is_unique", "entropy": 57.666148491909496}
{"candidate": "                codes, categories = factorize_from_iterable(key)\n                to_concat.append(codes.take(index.get_indexer(level)))\n            codes_list.append(np.concatenate(to_concat))\n\n        zipped_codes = list(zip(*codes_list))\n\n        concat_index = MultiIndex(\n            levels=levels, codes=zipped_codes, verify_integrity", "entropy": 27.54064688500157}
{"candidate": "                i = level.get_indexer(key)\n                if (i == -1).any():\n                    if isinstance(key, tuple):\n                        key = list(key)\n                    else:\n                        key = [key]\n                    raise KeyError(\n                        \"Key length ({len_keys}) was greater than \"\n                        \"MultiIndex lexsort depth ({lexsort_depth})\"\n                        \"\".format(len_keys=len(", "entropy": 24.451833856272692}
{"candidate": "                i = level.get_indexer(key)\n                if (i == -1).any():\n                    raise ValueError(\n                        f\"Key length ({len(key)}) exceeded Index depth ({index.nlevels})\"\n                    )\n                if i.ndim > 1 or index.nlevels > 1:\n                    # possible dup index\n                    i = com._ensure_platform_int(i)\n                    to_concat.", "entropy": 40.70882011179091}
{"candidate": "                codes = ensure_int64(level.get_indexer(key))\n                to_concat.append(codes)\n\n            codes_list.append(np.concatenate(to_concat))\n\n        concat_index = _concat_indexes(indexes)\n\n        # these go at the end\n        codes, categories = factorize_from_iterable(concat_index)\n        levels.append(c", "entropy": 13.635536240479702}
{"candidate": "                if not is_list_like(key):\n                    key = [key]\n\n                try:\n                    codes = com.get_level_codes(level, key)\n                except KeyError:\n                    # allow non-unique levels in the future\n                    # https://github.com/pandas-dev/pandas/issues/14264\n                    codes, level = factorize_from_iterables([key])\n                    if name is", "entropy": 73.22191497731411}
