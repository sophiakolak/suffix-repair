{"candidate": "        spider_manager_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n        return spider_manager_cls.from_settings(settings)\n    else:\n        return _get_spider_loader_class(settings)(settings)\n\n\ndef _get_spider_loader_class(settings):\n    \"\"\" Get SpiderLoader class from settings \"\"\"\n    if settings.get('SPIDER_LOADER_", "entropy": 11.482322857853003}
{"candidate": "        spider_loader_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        spider_loader_cls = load_object(settings['SPIDER_LOADER_CLASS'])\n    return spider_loader_cls.from_settings(settings)\n\n\ndef _get_scheduler_cls(settings):\n    scheduler_cls = load_object(settings['SCH", "entropy": 12.621931553011}
{"candidate": "        spider_manager_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n        return spider_manager_cls.from_settings(settings)\n    else:\n        return _get_spider_loader_by_default(settings)\n\n\ndef _get_spider_loader_by_default(settings):\n    \"\"\" Get default SpiderLoader instance \"\"\"\n    return load_object(settings['SPIDER_", "entropy": 15.403124132519995}
{"candidate": "        spider_loader_cls_path = settings.get('SPIDER_MANAGER_CLASS')\n    else:\n        spider_loader_cls_path = settings.get('SPIDER_LOADER_CLASS',\n                                              'scrapy.spiderloader.SpiderLoader')\n    return load_object(spider_loader_cls_path)(settings)\n\n\nclass CrawlerProcess(CrawlerRunner):\n    \"\"\"", "entropy": 16.230363063366998}
{"candidate": "        SpiderLoader = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoader = load_object(settings['SPIDER_LOADER_CLASS'])\n    return SpiderLoader.from_settings(settings)\n\n\ndef _get_crawler_process(settings, crawlers):\n    \"\"\" Get CrawlerProcess instance from settings and crawlers \"\"\"\n    if settings.get('CRAWLER_PROC", "entropy": 16.388759972057}
{"candidate": "        return _get_spider_manager(settings)\n    else:\n        return _get_spider_loader_class(settings).from_settings(settings)\n\n\ndef _get_spider_loader_class(settings):\n    return load_object(settings['SPIDER_LOADER_CLASS'])\n\n\ndef _get_spider_manager(settings):\n    warnings.warn(\n        'SpiderManager is deprecated and will be", "entropy": 16.879065092227}
{"candidate": "        cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        cls = load_object(settings['SPIDER_LOADER_CLASS'])\n    return cls.from_settings(settings)\n\n\ndef _get_scheduler_cls(settings):\n    \"\"\" Get Scheduler class from settings \"\"\"\n    scheduler_cls_path = settings.get('SCHEDUL", "entropy": 17.3880804641074}
{"candidate": "        SpiderLoader = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoader = load_object(settings['SPIDER_LOADER_CLASS'])\n    return SpiderLoader.from_settings(settings.frozencopy())\n\n\ndef _get_extensions_list(settings, key):\n    \"\"\" Get extension list from settings \"\"\"\n    ext = settings.getlist(key)\n    if not", "entropy": 18.341285739296005}
{"candidate": "        spider_manager_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        spider_manager_cls = load_object(settings['SPIDER_LOADER_CLASS'])\n    return spider_manager_cls.from_settings(settings)\n\n\ndef _get_scheduler(crawler):\n    \"\"\" Get scheduler instance from Crawler \"\"\"\n    warnings.warn('C", "entropy": 21.657348030538}
{"candidate": "        spider_loader_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n        return spider_loader_cls.from_settings(settings)\n\n    warnings.warn(\n        'Scheduler.from_settings is deprecated. '\n        'Please use SpiderLoader.from_settings.',\n        category=ScrapyDeprecationWarning, stacklevel=2\n    )\n    scheduler_cls", "entropy": 24.561875104160404}
{"candidate": "        warnings.warn(\n            'Importing from module \"scrapy.spidermanager\" is deprecated. '\n            'Please import from module \"scrapy.spiderloader\".',\n            category=ScrapyDeprecationWarning, stacklevel=2\n        )\n        from scrapy.spidermanager import SpiderManager\n        return SpiderManager.from_settings(settings)\n\n    from scrapy.spiderloader import SpiderLoader\n   ", "entropy": 25.049848508251003}
{"candidate": "        SpiderLoaderClass = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoaderClass = load_object(settings['SPIDER_LOADER_CLASS'])\n    return SpiderLoaderClass.from_settings(settings.frozencopy())\n\n\ndef _get_scraper_classes(spider_loader):\n    \"\"\" Get Scrapy spiders from spider manager \"\"\"\n    return spider_loader.list", "entropy": 25.277087318119}
{"candidate": "        spider_manager_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n        return spider_manager_cls.from_settings(settings)\n    else:\n        return _get_spider_loader_class(settings).from_settings(settings)\n\n\ndef _get_spider_loader_class(settings):\n    \"\"\" Get the default SpiderLoader class from the installed Scrapy eggs \"\"\"\n   ", "entropy": 26.934888648968}
{"candidate": "        SpiderLoader = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoader = load_object(settings['SPIDER_LOADER_CLASS'])\n    return SpiderLoader.from_settings(settings.frozencopy())\n\n\ndef _get_slot_and_spidercls(spider_loader, spider_name, required=True):\n    \"\"\" Get Slot instance and spider class from spider", "entropy": 27.118287899040002}
{"candidate": "        SpiderLoader = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoader = load_object(settings['SPIDER_LOADER_CLASS'])\n    return SpiderLoader.from_settings(settings)", "entropy": 19.313466513612003}
{"candidate": "        cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        cls = load_object(settings['SPIDER_LOADER_CLASS'])\n    return cls.from_settings(settings.frozencopy())\n\n\ndef _get_spider_queues(settings):\n    \"\"\" Get Queue and its data structure from settings \"\"\"\n    queuecls = load_object(settings['", "entropy": 31.720269533574942}
{"candidate": "        spider_manager_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n        return spider_manager_cls.from_settings(settings)\n    else:\n        return load_object(settings['SPIDER_LOADER_CLASS']).from_settings(settings)\n\n\ndef _get_extensions_list(settings, default_list=None):\n    \"\"\"\n    Get list of enabled extensions from CLI", "entropy": 33.12864680444599}
{"candidate": "        path = settings['SPIDER_MANAGER_CLASS']\n    else:\n        path = settings['SPIDER_LOADER_CLASS']\n    return loader.load_object(path)(settings)\n\n\ndef _get_engine(crawler, settings):\n    \"\"\"Return a Scrapy engine using the given crawler and settings\"\"\"\n    return ExecutionEngine(crawler, lambda _: reactor.stop())\n\n\ndef _create_crawler", "entropy": 33.585451667513}
{"candidate": "        spider_loader_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        spider_loader_cls = load_object(settings['SPIDER_LOADER_CLASS'])\n    return spider_loader_cls.from_settings(settings.frozencopy())\n\n\ndef _get_extensions_list(module):\n    # Get extensions and sort them according to their priority\n   ", "entropy": 35.309028357262996}
{"candidate": "        SpiderLoaderClass = load_object(settings['SPIDER_MANAGER_CLASS'])\n    else:\n        SpiderLoaderClass = load_object(settings['SPIDER_LOADER_CLASS'])\n\n    return SpiderLoaderClass.from_settings(settings)\n\n\ndef _is_debug_active(settings):\n    \"\"\" Check if debug mode is enabled \"\"\"\n    debug = False\n    if settings.getbool('DEBUG'):\n       ", "entropy": 36.91671965799199}
