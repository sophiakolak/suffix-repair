{"candidate": "                    output += f.extrabuf\n                except AttributeError:\n                    pass\n                break\n            raise\n    return output\n\n\ndef is_valid_url(url):\n    # Regex taken from the django URLValidator\n    regex = re.compile(\n        r'^(?:http|ftp)s?://'  # http:// or https://\n        r'(?:(?:[A-Z0-9", "entropy": 21.76738448504901}
{"candidate": "                    output += f.extrabuf\n                    f.extrabuf = b''\n                except AttributeError:\n                    pass\n                return output\n            else:\n                raise\n    return output\n\n\ndef is_gzipped(response):\n    ctype = response.headers.get('Content-Type', '').lower()\n    encoding = response.headers.get('Content-Encoding', '').lower()\n    return 'gzip' in", "entropy": 23.698503552938007}
{"candidate": "                    return output + f.extrabuf\n                except AttributeError:\n                    return output\n            else:\n                raise\n    return output\n\n\ndef remove_comments(text):\n    \"\"\" Remove C-style comments. \"\"\"\n    pattern = r\"\"\"\n                            ##  --------- COMMENT ---------\n           /\\*              ##  Start of /* ... */ comment\n           [^*]*\\*+         ##  Non-* followed by 1-", "entropy": 27.137247372549744}
{"candidate": "                    output += f.extrabuf\n                except AttributeError:\n                    pass\n                break\n            else:\n                raise\n    if not output:\n        raise IOError('Error decompressing data: data stream corrupted')\n    f.close()\n    return output\n\n\nclass HtmlResponse(Response):\n\n    def __init__(self, *args, **kwargs):\n        kwargs.setdefault('encoding', 'utf-", "entropy": 28.686593378592}
{"candidate": "                    output += f.extrabuf\n                except IOError:\n                    pass\n                return output\n            else:\n                raise\n\n\nclass HtmlGzipMiddleware(object):\n    def process_response(self, request, response, spider):\n        if 'gzip' not in response.headers.get('Content-Encoding', ''):\n            return response\n        data = gunzip(response.body)\n        if data:\n           ", "entropy": 29.22828139447699}
{"candidate": "                    f.close()\n                except IOError:\n                    pass\n                break\n            raise\n    return output\n\n\ndef is_html(data):\n    \"\"\"Returns True if the given data is HTML\"\"\"\n    return data.lstrip().startswith(b'<')\n\n\ndef is_xml(data):\n    \"\"\"Returns True if the given data is XML\"\"\"\n    return data.lstrip().startswith(b'<?xml')", "entropy": 29.333718477580003}
{"candidate": "                    output += f.extrabuf\n                except AttributeError:\n                    pass\n                break\n            else:\n                raise\n    return output\n\n\ndef gzip(data):\n    fileobj = BytesIO()\n    with GzipFile(fileobj=fileobj, mode='wb', compresslevel=5) as gzf:\n        gzf.write(data)\n    return fileobj.getvalue()\n\n\n_RE", "entropy": 29.589737304998998}
{"candidate": "                    f.close()\n                except (IOError, EOFError):\n                    pass\n                return output\n            raise\n    try:\n        f.close()\n    except (IOError, EOFError):\n        pass\n    return output\n\nclass HtmlResponse(Response):\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(crawler.settings.get('HTML_RESP", "entropy": 31.000706291392987}
{"candidate": "                    output += f.extrabuf\n                except AttributeError:\n                    pass\n                return output\n            else:\n                raise\n    return output\n\n\ndef get_base_url(response):\n    \"\"\"Return the ``base_url`` from the given response.\"\"\"\n    base_url = response.request.meta.get('base_url')\n    if not base_url:\n        url = urlparse_cached(response)\n", "entropy": 31.61903167007899}
{"candidate": "                    f.close()\n                except IOError:\n                    pass\n                break\n            else:\n                f.close()\n                raise\n    return output\n\n\ndef is_html(response):\n    \"\"\"Return True if content-type is some kind of HTML\"\"\"\n    ctype = response.headers.get('Content-Type', '').lower()\n    return 'html' in ctype or 'xml' in ctype\n\n\ndef text_html", "entropy": 34.897359888153}
{"candidate": "                    output += getattr(f, 'extrabuf', b'')\n                except struct.error:\n                    pass\n                break\n            else:\n                raise\n    return output\n\n\ndef parse_domain(domain):\n    \"\"\"\n    >>> parse_domain('http://www.google.com/')\n    'google.com'\n    >>> parse_domain('http://www.google.com/?q=test')\n    'google.", "entropy": 42.784732551417015}
{"candidate": "                    output += f.extrabuf\n                except Exception:\n                    pass\n                try:\n                    f.close()\n                except Exception:\n                    pass\n                return output\n            raise\n    f.close()\n    return output\n\n\ndef fix_line_ending(data):\n    \"\"\"\n    Make sure the line endings in the given byte string are CRLF (as per HTTP\n    specification.)\n    \"\"\"\n    if b'\\r", "entropy": 46.465125365205395}
{"candidate": "                    f.close()\n                except Exception:\n                    pass\n                return output\n            else:\n                raise\n\n\ndef safe_get(item, key):\n    if key in item:\n        return item[key]\n    else:\n        return ''\n\n\nif six.PY2:\n    def safe_text(text):\n        if isinstance(text, str):\n            return text\n        else:\n            return text.en", "entropy": 51.022862857756}
{"candidate": "                    # re-create the GzipFile object to get the remaining data\n                    f = GzipFile(fileobj=BytesIO(f.extrabuf))\n                    chunk = read1(f, 8196)\n                    output += chunk\n                except EOFError:\n                    break\n            elif chunk:\n                raise\n    return output\n\n\ndef _gzip_extension(filename):\n    if filename.endswith('.gz'", "entropy": 51.307471521142986}
{"candidate": "                    return output + f.extrabuf\n                except AttributeError:\n                    # python 2.7 compat\n                    return output + f.extras\n            raise\n    return output\n\n\n# Workaround for http://bugs.python.org/issue12260\ndef _fileobj_len(fileobj):\n    pos = fileobj.tell()\n    fileobj.seek(0, 2)  # seek end\n    size = fileobj.", "entropy": 55.474441163533}
{"candidate": "                    f.close()\n                except IOError:\n                    pass\n                return output\n            else:\n                raise\n\n\ndef resolve_base_href(response, response_text):\n    if response.encoding.lower() == \"utf-8\":\n        if six.PY2:\n            response_text = response_text.decode('utf-8')\n        else:\n            body_regex = re.compile(r", "entropy": 58.303054529328}
{"candidate": "                    return output + f.extrabuf\n                except AttributeError:  # python2\n                    return output + f.extrastart\n            six.reraise(*sys.exc_info())\n\n\n_spaces = re.compile(b'[ \\t]*\\n')\n_paras = re.compile(b'\\n(?:\\s*\\n)+')\n_sp = re.compile(b'\\", "entropy": 67.380690282049}
{"candidate": "                    return output + getattr(f, 'extrabuf', b'')\n                except AttributeError:\n                    # added in Python 3.3\n                    return output\n            six.reraise(*sys.exc_info())\n    # Python 3.3 support\n    return output + getattr(f, 'extrabuf', b'')\n\n\ndef get_url(url, default=None):\n    \"\"\"Try to fetch the given URL and", "entropy": 67.45881825855903}
{"candidate": "                    f.close()\n                except IOError:\n                    pass\n                return output\n            raise\n\n    return output\n\n\ndef _build_uri_regex():\n    \"\"\"\n    Builds regular expression for parsing URIs.\n\n    See: https://www.w3.org/Addressing/URL/url-spec.txt\n\n    Returns:\n        re: regular expression for parsing URIs.\n\n    \"\"\"\n    pattern = r'''\n", "entropy": 68.05699309562002}
{"candidate": "                    output += f.extrabuf\n                except EOFError:\n                    pass\n                break\n            else:\n                raise\n    return output\n\n\ndef _build_noerror(response):\n    return lambda *args, **kwargs: b''\n\n\nclass GZipMiddleware(object):\n    def process_response(self, request, response, spider):\n        if (response.headers.get('Content-Encoding', '').start", "entropy": 68.99586099529999}
