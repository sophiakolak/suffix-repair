{"candidate": "    def __init__(self, name, pid, module, tasks):\n        self.name = name\n        self.pid = pid\n        self.module = module\n        self.tasks = tasks\n        self.start_time = int(time.time())\n        self.last_seen = self.start_time\n\n    def __repr__(self):\n        return \"Worker(%r)\" % vars(self)\n\n\n", "entropy": 28.42404863290899}
{"candidate": "    def __init__(self, worker_id, worker, is_active=True, tasks=[]):\n        self.worker_id = worker_id\n        self.worker = worker\n        self.is_active = is_active\n        self.tasks = tasks\n\n    def __repr__(self):\n        return \"Worker(%r)\" % vars(self)\n\n    @property\n    def id(self):\n       ", "entropy": 32.86638293705151}
{"candidate": "    def __init__(self, name, timeout):\n        self.name = name\n        self.pid = None\n        self.last_seen = time.time()\n        self.timeout = timeout\n        self.task_map = {}\n\n    def __repr__(self):\n        return \"Worker(%r)\" % vars(self)\n\n    def add_task(self, task_id):\n        self.task_map", "entropy": 35.387021859234}
{"candidate": "    def __init__(self, name, log_level, log_file):\n        self.name = name\n        self.log_level = log_level\n        self.log_file = log_file\n        self.logger = get_logger(self.name)\n        self.logger.set_level(self.log_level)\n        self.logger.set_file(self.log_file)\n        self", "entropy": 37.03259461458603}
{"candidate": "    __slots__ = ['id', 'name', 'task', 'num_executed', 'num_failed', 'startup']\n\n    def __init__(self, id, name, task, num_executed, num_failed, startup):\n        self.id = id\n        self.name = name\n        self.task = task\n        self.num_executed = num_executed\n        self.num_failed = num_", "entropy": 40.50213215905796}
{"candidate": "    __slots__ = ('worker_id', 'task', 'connection', 'proxy', 'updated_at')\n\n    def __init__(self, worker_id, connection=None, proxy=None):\n        self.worker_id = worker_id\n        self.task = None\n        self.connection = connection\n        self.proxy = proxy\n        self.updated_at = None\n\n\nclass Failures(object):\n    \"\"\"\n   ", "entropy": 44.275817872632004}
{"candidate": "    def __init__(self):\n        self.tasks = []\n        self.active_tasks = {}\n        self.retries = []\n        self.last_seen = time.time()\n        self.num_tasks = 0\n        self.current_task = None\n        self.worker_id = None\n\n    def __repr__(self):\n        return \"Worker(%r)\" % vars(self)", "entropy": 51.25463358625902}
{"candidate": "    def __init__(self,\n                 name,\n                 hostname,\n                 process,\n                 pid,\n                 group,\n                 start_time,\n                 tasks,\n                 disk_check_failure):\n        self.name = name\n        self.hostname = hostname\n        self.process = process\n        self.pid = pid\n        self.group = group\n        self.start_time = start_time\n        self.", "entropy": 52.66297317618701}
{"candidate": "    def __init__(self, worker, level, queue):\n        \"\"\"\n        :param worker: worker reference\n        :type worker: CloudifyWorker\n        :param level: logging level for the worker\n        :type level: int\n        :param queue: queue for this worker\n        :type queue: queue.Queue\n        \"\"\"\n        self.worker = worker\n        self.level = level\n        self.queue = queue\n        self.", "entropy": 54.05297230969301}
{"candidate": "    def __init__(self, address, name, last_active,\n                 task_limit, processes, max_tasks_per_child,\n                 task_events=None):\n        self.address = address\n        self.name = name\n        self.first_active = last_active\n        self.last_active = last_active\n        self.task_limit = task_limit\n        self.processes = processes\n        self.", "entropy": 59.42453085925969}
{"candidate": "    def __init__(self, name):\n        self.name = name\n        self.path = '/' + name\n        self.tasks = []\n        self.active = False\n        self.disabled = False\n        self.disabled_tasks = []\n\n    def __repr__(self):\n        return \"Worker(%r)\" % vars(self)\n\n\ndef _maybe_disable_worker(worker, module_name", "entropy": 63.43478938498499}
{"candidate": "    def __init__(self, name, task_list=[],\n                 max_tasks=None, resources=None):\n        self.name = name\n        self.task_list = task_list\n        self.resources = _get_default(resources, {})\n        self.max_tasks = max_tasks\n        self.worker_count = 0\n        self.running_exec_count = 0\n        self.exec_", "entropy": 63.513820339538995}
{"candidate": "    def __init__(self, worker_name):\n        self.name = worker_name\n        self.reference = None\n        self.load = 0\n        self.enabled = False\n        self.tasks = dict()\n        self.unacked_tasks = dict()\n        self.last_queued_task = None\n        self.last_timestamp = None\n\n    def __repr__(self):\n        return \"Work", "entropy": 67.03654691267596}
{"candidate": "    def __init__(self, task, ioloop, start_time):\n        \"\"\"\n        Initialize\n        :param task: The Celery task running inside this worker\n        :param ioloop: The associated tornado ioloop\n        :param start_time: The time that this worker started\n        \"\"\"\n        self.task = task\n        self.start_time = start_time\n        self.ioloop = ioloop\n       ", "entropy": 69.86054792464617}
{"candidate": "    def __init__(self, name, thread, task_queue, rpc_config):\n        self.name = name\n        self.thread = thread\n        self.task_queue = task_queue\n        self.rpc_config = rpc_config\n        self.stopped = False\n\n\nclass TaskQueue(deque):\n    \"\"\"\n    A priority queue of Tasks, that is a queue with priorities.\n    \"\"\"\n\n   ", "entropy": 76.35421946058173}
{"candidate": "    def __init__(self, worker_id, stop_event, workers,\n                 worker_threads, tasks_map):\n        \"\"\"\n        @param worker_id: unique string for identifying the worker\n        @param stop_event: threading.Event for stopping the worker\n        @param worker_threads: map of worker_id -> threading.Thread\n        @param tasks_map: map of task_id -> Task\n        \"\"\"\n\n", "entropy": 77.739445775183}
{"candidate": "    def __init__(self, task, q_worker_to_task=None,\n                 q_task_to_worker=None,\n                 q_worker_to_manager=None,\n                 q_manager_to_worker=None,\n                 id=None,\n                 pid=None,\n                 timeout=None,\n                 frequency=None,\n                 start_time=None,\n                 end_time=None,\n                 start_", "entropy": 78.63986948466598}
{"candidate": "    def __init__(self,\n                 name,\n                 task_preferences,\n                 hard_task_limit,\n                 hard_memory_limit,\n                 hard_cpu_limit,\n                 hard_log_limit,\n                 hard_running_time_limit,\n                 work_enabled=True,\n                 version=None,\n                 os_name=None,\n                 os_version=None,\n                 hostname=None,\n", "entropy": 85.83400132293897}
{"candidate": "    def __init__(self, name, data, queue, error_queue,\n                 heartbeat_callback, queue_callback, drain_callback,\n                 drain_timeout, drain_callback_timeout,\n                 continuous=False, **kwargs):\n        \"\"\"\n        Constructor.\n\n        :param name: Worker name.\n        :param data: Worker data.\n        :param queue: Queue to get tasks from.\n        :param error_queue", "entropy": 94.32886442699298}
{"candidate": "    def __init__(self, task_id, task, resource_kwargs, run_kwargs,\n                 pre_run_func, post_run_func, on_terminate_func,\n                 failure_func, params,\n                 self_destruct=False, pipe=None, debug=False):\n        self.task_id = task_id\n        self.task = task\n        self.resource_kwargs = resource_kwargs", "entropy": 98.65691776974448}
