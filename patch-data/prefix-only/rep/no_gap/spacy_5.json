{"candidate": "                pipe.pipe(docs, golds=golds, **kwargs)\n            else:\n                pipe.pipe(docs, **kwargs)\n        scorer.score(docs, golds, verbose=verbose)\n        return scorer\n\n    def evaluate_rehearsal(\n        self,\n        docs_golds,\n        verbose=False,\n        batch_size=256,\n        scorer=None,\n        component", "entropy": 20.86143955532498}
{"candidate": "                pipe(docs, golds, **kwargs)\n                continue\n            batch_docs = [docs[i : i + batch_size] for i in range(0, len(docs), batch_size)]\n            batch_golds = [golds[i : i + batch_size] for i in range(0, len(docs), batch_size)]\n            for i, batch_doc in enumerate(batch_docs):\n               ", "entropy": 21.184154054006598}
{"candidate": "                with self.use_params(optimizer=self.optimizer, **kwargs):\n                    scorer.score(pipe, docs, golds, verbose=verbose)\n            else:\n                for sub_pipe in pipe.pipe:\n                    with self.use_params(optimizer=self.optimizer, **kwargs):\n                        scorer.score(sub_pipe, docs, golds, verbose=verbose)\n        return", "entropy": 21.598006360422577}
{"candidate": "                pipe(docs, golds, **kwargs)\n            else:\n                pipe.pipe(docs, golds, **kwargs)\n        if verbose:\n            print(scorer.print_scores())\n        return scorer\n\n    def evaluate_rehearsal(\n        self,\n        docs_golds,\n        verbose=True,\n        batch_size=256,\n        scorer=None,\n        component_", "entropy": 24.745501131353993}
{"candidate": "                pipe(docs, **kwargs)\n            else:\n                for proc in pipe.pipe:\n                    proc(docs, **kwargs)\n            scorer.score(docs, golds, verbose=verbose, component=name)\n        return scorer\n\n    def train(\n        self,\n        docs,\n        drop=0.2,\n        sgd=None,\n        losses=None,\n        component_cfg=None,", "entropy": 25.424930650266003}
{"candidate": "                scorer.scores.setdefault(name, {})\n                pipe.evaluate(docs, golds, scorer.scores[name], verbose, **kwargs)\n            else:\n                for proc in pipe.pipe:\n                    proc_name = name + \"-\" + proc.name\n                    scorer.scores.setdefault(proc_name, {})\n                    proc.evaluate(docs, golds, scorer.scores[proc_", "entropy": 25.809526414937494}
{"candidate": "                if pipe is golds[0]:\n                    for doc, gold in zip(docs, golds):\n                        scorer.score(doc, gold, name=name, verbose=verbose)\n                else:\n                    for doc in pipe.pipe(docs, **kwargs):\n                        scorer.score(doc, golds[0], name=name, verbose=verbose)\n            else:\n                docs = pipe.pipe(docs,", "entropy": 29.671567264012}
{"candidate": "                continue\n            scorer = pipe.pipe(docs, golds, scorer, verbose, **kwargs)\n        return scorer\n\n    def pipe(\n        self,\n        docs,\n        batch_size=1000,\n        n_threads=2,\n        disable=tuple(),\n        drop=0.0,\n        as_tuples=False,\n        n_process=0,\n    ):\n        \"\"\"Process texts as", "entropy": 30.5193136030184}
{"candidate": "                scorer.add_scores(pipe.evaluate(docs, golds, **kwargs))\n            else:\n                scorer.add_scores(pipe.pipe.evaluate(docs, golds, **kwargs))\n        if verbose:\n            for name, score in scorer.scores.items():\n                if isinstance(score, float):\n                    print(\"{:30}: {:.3f}\".format(name, score))", "entropy": 33.53193146491099}
{"candidate": "                pipe = [pipe]\n            for proc in pipe:\n                proc.eval(docs, golds, scorer, verbose=verbose, **kwargs)\n        return scorer\n\n    def pipe(self, docs, batch_size=1000, n_threads=2, verbose=False):\n        \"\"\"Process texts as streamed documents.\n\n        docs (iterable): Document texts.\n        batch_size (int): Number of documents to collect", "entropy": 35.50423766980399}
{"candidate": "                if verbose:\n                    print(f\"Component '{name}':\")\n                pipe.pipe(docs, golds, verbose=verbose, **kwargs)\n            else:\n                if verbose:\n                    print(f\"Pipeline '{pipe.name}':\")\n                pipe.pipe(docs, golds, verbose=verbose, **kwargs)\n            if verbose:\n                print(f\"", "entropy": 36.228478286656006}
{"candidate": "                pipe(docs, **kwargs)\n            elif hasattr(pipe, \"eval\"):\n                pipe.eval(docs, **kwargs)\n            else:\n                for doc in pipe.pipe(docs, **kwargs):\n                    pass\n            if name in golds[0]:\n                scores = scorer.score(docs, golds, verbose=verbose)\n                return scores\n        if verbose:\n            print(", "entropy": 41.43824588395301}
{"candidate": "                docs = pipe.process(docs, **kwargs)\n            else:\n                # Old deprecated code path.\n                docs = list(pipe.pipe(docs, **kwargs))\n        scorer.score(docs, golds, verbose=verbose)\n        return scorer\n\n    def update(self, docs, golds, sgd=None, losses=None, drop=0.2, drop_factor=0.2):\n       ", "entropy": 47.45660948005249}
{"candidate": "                pipe.pipe(docs, **kwargs)\n            else:\n                pipe.pipe(docs, golds, **kwargs)\n            scorer.scores.update(pipe.scores)\n            docs = list(pipe.docs)\n            golds = list(pipe.golds)\n        if verbose:\n            print(end=\"\\r\\n\")\n            print(scorer.format_results(self.name))\n", "entropy": 48.478943665985}
{"candidate": "                pipe.model = self.get_pipe(name)\n                pipe.pipe(docs, golds, verbose=verbose, **kwargs)\n        return scorer\n\n    def from_disk(self, path):\n        \"\"\"Load and return a model from the given path.\n\n        path (unicode): The location of the model data.\n        RETURNS (Language): The loaded `Language` object.\n        \"\"\"\n        with open(", "entropy": 48.73395030341101}
{"candidate": "                pipe.pipe_score(docs, golds, verbose=verbose, **kwargs)\n                continue\n            if verbose:\n                logger.info(\"Processing pipeline component %r\" % name)\n            sub_docs = pipe.pipe(\n                docs, golds, as_tuples=True, verbose=verbose, **kwargs\n            )\n            if golds:\n                scorer.score(sub_docs,", "entropy": 52.589738095313194}
{"candidate": "                pipe(docs, **kwargs)\n            else:\n                pipe.pipe(docs, **kwargs)\n        scorer.score(docs, golds)\n        if verbose:\n            print(scorer.json)\n        return scorer\n\n    def explain(self, doc, attrs=None, **kwargs):\n        \"\"\"Print a detailed, internal analysis of a given Doc.\n\n        doc (Doc): A Doc object.\n       ", "entropy": 53.73758521656001}
{"candidate": "                pipe = pipe.__call__\n            pipe(docs, golds, **kwargs)\n        scorer.score(docs, golds, verbose)\n        return scorer\n\n    def make_doc(self, text):\n        \"\"\"Create a `Doc` from unicode text.\"\"\"\n        attrs = dict()\n        for w_id, w in enumerate(reversed(text.split())):\n            if w_id:", "entropy": 60.390287283043}
{"candidate": "                continue\n            if not pipe.pipe:\n                continue\n            for proc in pipe:\n                if verbose:\n                    print(\"Running component %s\" % proc.name)\n                predictor = proc.get_predictor(**kwargs)\n                docs = predictor.pipe(docs)\n                scorer.score(docs, golds, proc.name)\n                docs, golds = (list(docs), list(golds))\n", "entropy": 63.58881949366096}
{"candidate": "                pipe.pipe(docs, golds, **kwargs)\n            else:\n                pipe.evaluate(docs, golds, **kwargs)\n            if verbose:\n                logger.info(name.upper())\n            scorer.score(docs, golds, verbose)\n            # Clear predictions on non-head components\n            if name in self.non_head_components:\n                pipe.clear(docs)\n        return scorer", "entropy": 64.63255737416999}
